# ME Engineering Assistant

A production-ready **Retrieval-Augmented Generation (RAG)** system that answers engineering questions using ECU (Electronic Control Unit) technical manuals.

This project demonstrates:
- Local LLM inference (Phi-3 Mini)
- Multi-document RAG
- Query routing across multiple ECU models
- FastAPI RESTful service
- MLflow model packaging & serving
- **Dockerfile template (experimental, not fully validated yet)**

The system runs fully **offline**, making it suitable for on-premise or restricted environments.

---

## ğŸ” 1. Overview

Modern engineering teams often rely on large, unstructured PDF/manual collections.  
**ME Engineering Assistant** turns ECU manuals into an intelligent Q&A assistant powered by:

- Embedding-based retrieval  
- Query routing  
- Lightweight local LLM reasoning  

The system supports the following manuals:

- ECU-700 Series
- ECU-800 Base
- ECU-800 Plus

Routing ensures each query is answered using the most relevant manual family.

---

## âœ¨ 2. Key Features

### âœ” Multi-manual RAG  
Automatically routes each question to the correct ECU manual family using rule-based classification.

### âœ” Local Phi-3 LLM  
Runs fully offline using `microsoft/Phi-3-mini-4k-instruct` on CPU or Apple Silicon (MPS + BF16).

### âœ” Efficient Vector Search  
Uses HuggingFace embeddings + Chroma vectorstore for high-recall context retrieval.

### âœ” Modular LangGraph Workflow  
Separates concerns: routing â†’ retrieval â†’ answer generation.

### âœ” MLflow Model Packaging  
Exports the entire pipeline as a custom pyfunc model with versioning + prod alias.

### âœ” REST API with FastAPI  
Provides a standard /predict endpoint.

### âšª Docker (Experimental)  
A Dockerfile is provided as a **work-in-progress template**.  
It is not yet fully validated end-to-end and may require additional configuration.

---

## ğŸ“‚ 3. Repository Structure

```text
me-engineering-assistant/
â”‚
â”œâ”€â”€ README.md                      # Project documentation
â”œâ”€â”€ pyproject.toml                 # Dependencies & build config
â”œâ”€â”€ dockerfile                     # Docker build instructions (experimental)
â”œâ”€â”€ project_tree.txt               # Auto-generated project structure
â”‚
â”œâ”€â”€ data/                          # ECU manuals + test questions
â”‚   â”œâ”€â”€ ECU-700_Series_Manual.md
â”‚   â”œâ”€â”€ ECU-800_Series_Base.md
â”‚   â”œâ”€â”€ ECU-800_Series_Plus.md
â”‚   â””â”€â”€ test-questions.csv
â”‚
â”œâ”€â”€ mlruns/                        # Local MLflow tracking directory
â”‚   â””â”€â”€ ... (multiple registered runs/models)
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ me_engineering_assistant/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ __main__.py            # FastAPI entrypoint
â”‚       â”œâ”€â”€ api.py                 # REST handlers
â”‚       â”œâ”€â”€ config.py
â”‚       â”œâ”€â”€ data_loader.py
â”‚       â”œâ”€â”€ graph.py               # LangGraph orchestration (router â†’ RAG)
â”‚       â”œâ”€â”€ log_model.py           # MLflow model logging utility
â”‚       â”œâ”€â”€ mlflow_model.py        # MLflow pyfunc interface
â”‚       â”œâ”€â”€ rag_chain.py           # Retrieval + LLM generation
â”‚       â”œâ”€â”€ router.py              # Document routing logic
â”‚       â”œâ”€â”€ sandbox_test.py        # Simple local CLI test
â”‚       â””â”€â”€ vectorstore.py         # Embeddings + vectorstore builder
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_agent_e2e.py          # End-to-end verification
```

---


## ğŸ§  4. System Architecture

![ME Engineering Assistant Architecture](me_engineering_assistant_architecture.svg)

---

## âš™ï¸ 5. Installation

### 5.1 Clone the repository

```bash
git clone <repo-url>
cd me-engineering-assistant
```

### 5.2 Create a Python 3.11 virtual environment

```bash
python3.11 -m venv .venv
source .venv/bin/activate
```

### 5.3 Install dependencies

```bash
pip install .
```

For development mode:
```bash
pip install -e .
```

---

## ğŸš€ 6. Running Locally (CLI)

```bash
python -m me_engineering_assistant.sandbox_test
```
Example output:
```vbnet
Question: What is the maximum operating temperature for the ECU-850b?
Answer: The maximum operating temperature for the ECU-850b is +105Â°C.
```

---

## ğŸŒ 7. Start the FastAPI Server

```bash
python -m me_engineering_assistant
```
The server will start at:
```bash
http://localhost:8000/predict
```

---

## ğŸ“¡ 8. Example API Requests

### 8.1 cURL

```bash
curl -X POST http://localhost:8000/predict \
     -H "Content-Type: application/json" \
     -d '{"questions": ["What is the maximum operating temperature of the ECU-850b?"]}'
```

### 8.2 Python

```python
import requests

resp = requests.post(
    "http://localhost:8000/predict",
    json={"questions": ["What is the maximum operating temperature of the ECU-850b?"]}
)
print(resp.json())
```

### 8.3 Postman

* POST ```http://localhost:8000/predict```
* Body (JSON)
```json
{
  "questions": ["What is the maximum operating temperature of the ECU-850b?"]
}
```

---

## ğŸ“¦ 9. MLflow Model Logging & Loading

### Log the model
```bash
python -m me_engineering_assistant.log_model
```
This will:
- Log the full agent pipeline
- Create a new version in MLflow Model Registry
- Update the prod alias

Example output:
```bash
Created version '7' of model 'me-engineering-assistant'
alias = prod
```

### Recommended MODEL_URI for serving
```bash
models:/me-engineering-assistant@prod
```

### Load the model in Python
```python
import mlflow.pyfunc
model = mlflow.pyfunc.load_model("models:/me-engineering-assistant@prod")
```

### FastAPI with MODEL_URI
```bash
export MODEL_URI="models:/me-engineering-assistant@prod"
python -m me_engineering_assistant
```

---

## ğŸ§ª 10. Testing & Validation Strategy

### Included automated tests

```test_agent_e2e.py``` validates:

- Routing correctness
- Retrieval behavior
- Final answer quality
- End-to-end execution stability

Run tests:
```bash
pytest -q
```

---

## ğŸ³ 11. Containerization (Experimental)

A Dockerfile is included as a template, but not yet fully validated.

Example usage:
```bash
docker build -t me-assistant .
docker run -p 8000:8000 \
    -e MODEL_URI=models:/me-engineering-assistant@prod \
    me-assistant
```

Areas requiring further work:
- Preloading Phi-3 model
- MLflow filesystem mounting
- Performance tuning inside container

---

## âš ï¸ 12. Limitations

- Phi-3 may hallucinate on ambiguous questions
- Router is rule-based (no embedding classifier yet)
- Vectorstore rebuilt at runtime (non-persistent)
- Docker build still experimental
- No streaming answer support

---

## ğŸš§ 13. Future Work

### MLOps Enhancements

- Fully hardened Docker deployment
- MLflow model serving (```mlflow models serve```)
- Upgrade to SQLite/Postgres backend


### Agent Improvements

- Embedding-based router classifier
- Human-in-the-loop validation
- Multi-step reasoning with tool use
- Support more ECU manual families

### Retrieval Performance

- Persistent FAISS/Chroma index
- Quantized Phi-3 for faster inference

---

## ğŸ 14. Challenge Requirements Alignment

| Requirement                 | Status                                 |
| --------------------------- | -------------------------------------- |
| Multi-source RAG            | âœ” Implemented                          |
| Intelligent routing         | âœ” Router node                          |
| LangGraph agent             | âœ” Two-node workflow                    |
| MLflow model logging        | âœ” Custom pyfunc, versioned, prod alias |
| REST API                    | âœ” FastAPI `/predict`                   |
| Dockerization               | âšª Template included (experimental)     |
| Architectural documentation | âœ” Included                             |
| Testing strategy            | âœ” Automated + proposed framework       |
| Limitations & future work   | âœ” Documented                           |

---

## ğŸ™Œ Acknowledgements

- Microsoft Phi-3 Model
- LangChain / LangGraph
- MLflow
- ChromaDB